{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python NLP Tutorial \n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial was designed as a training tool for the HERC NLP Team and serves as a basic introduction to:\n",
    "\n",
    "* Python programming concepts\n",
    "* Implementation of natural language processing (NLP)\n",
    "* Popular Python libraries and data constructs used in data analytics\n",
    "* NLP applications towards healthcare\n",
    "\n",
    "This tutorial assumes basic understanding of programming techniques, syntax, and structures, whether in Python or another language.\n",
    "\n",
    "### Tools\n",
    "\n",
    "This tutorial uses an application called Jupyter Notebook as the programming interface. Jupyter is an interactive development environment that allows users to create and modify dynamic code \"cells\" and run them individually. This allows for easy experimentation and testing of code. The cells below have instructions and guidelines on how to manipulate the code for various results. You are also free to experiment on your own.\n",
    "\n",
    "### Notes\n",
    "\n",
    "* Each of these sections of text or code represent a cell. You will see the cell outlined when you click on it.\n",
    "* Any text that is [underlined]() is a link, usually to a reference page that provides more information about a given module or function.\n",
    "* A cell can be run by pressing `Ctrl + Enter` or by clicking the \"Run\" button on the toolbar above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports\n",
    "\n",
    "The first step in a Python program is to declare any external modules that will be used by the code. A module is a name for any file that contains Python code. A group of modules is often referred to as a library. A lot of the work we need has already been accomplished by others, so we can just download and reference their code (modules) for our own programs. We will be using the following modules:\n",
    "\n",
    "### re\n",
    "The [`re`](https://docs.python.org/3/library/re.html) module will allow us to search text using regular expressions, an approach to pattern recognition. These will be explained in greater depth below.\n",
    "\n",
    "### pandas\n",
    "The [`pandas`](https://pandas.pydata.org) module provides objects and methods that will allow us to efficiently structure and analyze large data sets. The primary structure is called a DataFrame, a 2D tabular object that allows for high performance of complex operations. A user-friendly tutorial can be found here: https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare an import using the keyword 'import'\n",
    "# Select this cell (blue or green outline) and press 'ctrl + enter' to run\n",
    "\n",
    "import re\n",
    "import pandas as pd  # we use the 'as' keyword to declare a shortcut to reference the pandas module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Input\n",
    "\n",
    "The first step to analyzing data is to input the data. We will be working with an extract from the [FDA MAUDE database](https://www.fda.gov/medical-devices/mandatory-reporting-requirements-manufacturers-importers-and-device-user-facilities/manufacturer-and-user-facility-device-experience-database-maude), which features adverse event reports involving medical devices. This extract specifically includes reports that contain the word \"EPIC\", intended to reference EPIC software.\n",
    "\n",
    "We will read our data from a CSV file ('EPIC_MAUDE.csv') and load it into our program using the [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) method. This will translate the file into a DataFrame that can be accessed for our analysis.\n",
    "\n",
    "After we read the data, we can view the output to make sure it's formatted correctly. In Jupyter Notebook, the final command of a cell will display its output (if applicable) every time you run that cell. We thus use the final command in the below cell to display the data using bracket notation. Python, like most mainstream languages, is 0-indexed, meaning that the first element of a list is referenced with the number \\[0\\], the second with \\[1\\], and so on. With a pandas DataFrame, we can access a subsection, or \"slice\" of the data, using colon notation `[start_index:stop_index]`. Play around with the example below using different values and observe what the output looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mdr_report_key</th>\n",
       "      <th>ID</th>\n",
       "      <th>ed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2643378</td>\n",
       "      <td>7806</td>\n",
       "      <td>\" /// IT WAS REPORTED THAT DURING A STENTING T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3108668</td>\n",
       "      <td>20011</td>\n",
       "      <td>/// THE SITE INDICATED THAT DURING A PERCUTAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2993514</td>\n",
       "      <td>22796</td>\n",
       "      <td>\" /// SAME CASE AS MFR REPORT #: 2134265-2013-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2993516</td>\n",
       "      <td>22798</td>\n",
       "      <td>\" /// SAME CASE AS MFR REPORT #: 2134265-2013-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030674</td>\n",
       "      <td>37547</td>\n",
       "      <td>/// IT WAS REPORTED, THE VALVE WAS EXPLANTED ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3450535</td>\n",
       "      <td>42739</td>\n",
       "      <td>/// IT WAS REPORTED THAT PREMATURE STENT DEPL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3201470</td>\n",
       "      <td>46335</td>\n",
       "      <td>/// THE VALVE WAS EXPLANTED DUE TO A CUSPAL T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3201484</td>\n",
       "      <td>46340</td>\n",
       "      <td>/// THE PT PRESENTED WITH CENTRAL LEAKAGE OF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3201492</td>\n",
       "      <td>46343</td>\n",
       "      <td>/// THE INFORMATION PROVIDED TO SJM INDICATED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3201525</td>\n",
       "      <td>46348</td>\n",
       "      <td>/// THE PATIENT PRESENTED WITH A HIGH GRADIEN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mdr_report_key     ID                                            ed_text\n",
       "0         2643378   7806  \" /// IT WAS REPORTED THAT DURING A STENTING T...\n",
       "1         3108668  20011   /// THE SITE INDICATED THAT DURING A PERCUTAN...\n",
       "2         2993514  22796  \" /// SAME CASE AS MFR REPORT #: 2134265-2013-...\n",
       "3         2993516  22798  \" /// SAME CASE AS MFR REPORT #: 2134265-2013-...\n",
       "4         2030674  37547   /// IT WAS REPORTED, THE VALVE WAS EXPLANTED ...\n",
       "5         3450535  42739   /// IT WAS REPORTED THAT PREMATURE STENT DEPL...\n",
       "6         3201470  46335   /// THE VALVE WAS EXPLANTED DUE TO A CUSPAL T...\n",
       "7         3201484  46340   /// THE PT PRESENTED WITH CENTRAL LEAKAGE OF ...\n",
       "8         3201492  46343   /// THE INFORMATION PROVIDED TO SJM INDICATED...\n",
       "9         3201525  46348   /// THE PATIENT PRESENTED WITH A HIGH GRADIEN..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you get an error running this cell, make sure you've run the imports cell first\n",
    "\n",
    "data = pd.read_csv('EPIC_MAUDE.csv')\n",
    "# print(data[0:10])  # uncomment this line by removing the first '#' symbol at the beginning\n",
    "data[0:10]  # try entering different numbers and re-running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use the [`print`](https://docs.python.org/3/library/functions.html#print) function to output data from any part of a cell. Try to uncomment the line `print(data[0:10])` in the cell above and re-run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the Data\n",
    "\n",
    "### Regular Expressions Intro\n",
    "The next step is to closer examine the data. We do some preliminary investigations to see what is notable or interesting about the data, anything that stands out or presents a feasible direction for our analysis. For quantitative data, this would often involve descriptive statistics, histograms, and the like, but for text based data, the approach is more driven by the content of the data or the type of problem we are trying to solve. In this case, we are looking at reports related to EPIC, so let's look for occurrences of the word \"Epic\".\n",
    "\n",
    "We will use a search pattern technique called [regular expressions](https://en.wikipedia.org/wiki/Regular_expression). The [`search`](https://docs.python.org/3/library/re.html#re.search) function allows us to search a text string for a given pattern. It has two required arguments: 1) the search pattern and 2) the text to be searched. It then returns a [match object](https://docs.python.org/3/library/re.html#match-objects) that contains information about any matches in the text string. Searching is case sensitive by default, so we can circumvent this issue by making our pattern and search text both lowercase. In the cell below, we set our pattern to search for the string \"epic\". We will select the first record in our data file as the search string. Run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(316, 320), match='epic'>\n"
     ]
    }
   ],
   "source": [
    "pattern = 'epic'\n",
    "text = data['ed_text'][0].lower()  # notation to read the first record of the 'ed_text' column and lowercase the text\n",
    "match = re.search(pattern, text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Match Objects\n",
    "\n",
    "When the code above runs, it prints the match object that is returned. The segment `span=(316, 320)` tells us that the search pattern was located between character 316 and 320 in text. For this to be practically useful, we can create a function that prints the surrounding text, just to give us the context that the word was used in. It will take two inputs, 1) a match object and 2) the window size (denoting how much surrounding text to show). The function will then output a string that contains the matched word and its context based on the inputs. We can then use a loop to examine several records this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ormed. the 6.0x61mm epic stent was advanced \n"
     ]
    }
   ],
   "source": [
    "def context(match, window=25):  # window size variable defaults to 25 if not explicitly given\n",
    "    start_index = max(0, match.start() - window)  # to prevent a negative number assignment\n",
    "    end_index = match.end() + window\n",
    "    \n",
    "    return match.string[start_index:end_index]\n",
    "\n",
    "print(context(match, 20))  # try different values for the window size variable to see what a helpful window looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laced with a smaller sjm epic bioprosthesis.\n",
      "fusion was ordered using epic software for a (b)(6) pt \n",
      "andards. we were told by epic who outsources the formul\n",
      " from the patient and an epic self expanding stent was \n",
      "acement of three 7x120mm epic self-expanding stents res\n",
      "acement of three 7x120mm epic self-expanding stents res\n",
      "acement of three 7x120mm epic self-expanding stents res\n",
      "erted the 7.0x118mm 75cm epic vas stent delivery system\n",
      "oblems with one bed 2030 epic ii. the fowler cannot be \n",
      " /// an sjm epic heart valve (model e100-2\n",
      "nd placement of a 9x61mm epic study stent. post dilatio\n",
      "n inserted a 8 x 41 x 75 epic self expanding stent in a\n",
      "de of ai. in 2008, a smj epic was implanted which in ti\n",
      "nd placed a 8 x 41 x 120 epic ide stent in the lesion. \n",
      "nd placed a 8 x 41 x 120 epic ide stent in the lesion. \n",
      " /// the epic supra valve was explanted\n",
      "s reported the 23 mm sjm epic supra was explanted due t\n",
      "yed. the zipwire and the epic were removed together as \n",
      "d in the iliac artery. 2 epic biliary 8x41mm stents wer\n",
      "d in the iliac artery. 2 epic biliary 8x41mm stents wer\n",
      " pt received a 23 mm sjm epic supra valve. haemoculture\n",
      "cian felt the tip of the epic self-expanding nitinol st\n",
      "cian felt the tip of the epic self-expanding nitinol st\n",
      " anticoagulation. an sjm epic bioprothesis was implante\n",
      "ian noted the tip of the epic self-expanding nitinol st\n"
     ]
    }
   ],
   "source": [
    "pattern = 'epic'\n",
    "matches = []  # create an empty list\n",
    "\n",
    "# iterate through reports and return a list of match objects (for positive matches) \n",
    "for text in data['ed_text']:  # loop through entire 'ed_text' column\n",
    "    match = re.search(pattern, text.lower())\n",
    "    if match is not None:\n",
    "        matches.append(match)  # add the match object to the list\n",
    "            \n",
    "for match in matches[:25]:  # loops through first 25 matches, change this value if you like\n",
    "    print(context(match))  # add a second argument for window size or change the default (and rerun the cell) in the function above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going Deeper, Part I\n",
    "\n",
    "We can immediately see that there are several reports we are not interested in. Since we searched for the term \"epic\", we are seeing reports related to \"Epic vascular stent system\". Here is where we begin to see the power of regular expressions. We can use them to make our search more precise, so it picks up occurrences of the word \"epic\" that are not followed by terms related to the vascular stent system. Looking at the output from above, we can see a few words we may want to filter out-- \"vascular\", \"stent\", \"valve\", etc.\n",
    "\n",
    "We can get this done using a _negative lookahead assertion_, which matches if the following text does not match the given expression. This means we can look for text that matches \"epic\", but does _not_ match \"vascular\", \"stent\", or \"valve\". The syntax for this assertion is `(?!<expression>)`. We can identify multiple words to avoid using the `|` character. Replace line 1 in the above code cell with\n",
    "\n",
    "    pattern = 'epic (?!stent|valve|vascular|sds|implant)'\n",
    "    \n",
    "and rerun the code to see what happens. You can also add or remove terms from the expression to see how it changes the results.\n",
    "\n",
    "You can find an overview of regular expression syntax here: https://docs.python.org/3/library/re.html#regular-expression-syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going Deeper, Part II\n",
    "\n",
    "You can see that the negative lookahead assertion removed some of the unwanted reports, but still leaves a lot of noise. We can keep adding terms to the assertion but if we look closely at the results, we see that there are often additional words between \"epic\" and one of our filter terms (e.g. \"epic self-expanding stents\", \"epic heart valve\"). So a cleaner approach would be to account for this word gap, regardless of what the interceding words are. A quick approach is to add a secondary filter step, that would remove reports that contain one of our \"negative\" keywords nearby the word \"epic\".\n",
    "\n",
    "In this case, we are creating a secondary pattern that, if matched, will pass over that report instead of adding it to our list of matches. The code for this algorithm is below. Note line 2:\n",
    "\n",
    "    negative_pattern = 'epic ([^.!?]+ ){0,5}?(stent|valve|vascular|sds|implant)'\n",
    "\n",
    "This is beginning to look pretty complicated, so let's break it down.\n",
    "* We first have `epic `, which, as before, looks for the word \"epic\", followed by a space.\n",
    "* Next is this bizarre pattern `([^.!?]* )`. This essentially matches a word, excluding any end punctuation.\n",
    "* The following `{0,5}?` tells it to match the previous pattern, `([^.!?]* )` anywhere between 0 and 5 times. This allows between zero and five words between the word \"epic\" and one of our exclusionary words, as long as there is no end punctuation.\n",
    "* Finally, we have our list of exclusionary words `(stent|valve|vascular|sds|implant)`.\n",
    "\n",
    "You can find a helpful demonstration [here](https://www.regexpal.com/?fam=111616), which highlights matched terms from a selection of reports. The link also allows you to edit the expression and see how the matched results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fication and moderate tortuosity. first, a stent (epic, boston scientific) was placed in the lesion. for\n",
      "d due to thrombus and replaced with a smaller sjm epic bioprosthesis.\n",
      " situation: a fentanyl infusion was ordered using epic software for a (b)(6) pt at a rate of 2 mcg/kg/hr\n",
      "ic medical record that we use in our institution -epic- defaults this as the default dosing. we had more\n",
      " /// customer reports problems with one bed 2030 epic ii. the fowler cannot be raised and lowered elect\n",
      " /// it was reported the 23 mm sjm epic supra was explanted due to stenosis. the physicia\n",
      "te since the installation of wireless laptops for epic. the monitor will display a normal ecg and then s\n",
      " /// epic ii bed checked according to customer complaint th\n",
      " /// epic ii bed check according to customer complaint that\n",
      " /// epic ii bed checked according to customer complaint th\n",
      " /// epic ii bed checked according to customer complaint th\n",
      " /// epic ii bed checked according to customer complaint th\n",
      "the wrong end. this was documented on the emar in epic. charge rn and pharmacy informed. on 0900 syringe\n",
      "ient c: patient is still in hospital and with new epic system could not find any dictation even with med\n",
      "stitis. the pt while in the operating room had an epic universal clip applier used. the clip applier was\n",
      "report for the previous surgery and a copy of the epic care expiration summary were received. per the op\n",
      "report for the previous surgery and a copy of the epic care expiration summary were received. per the op\n",
      "ed states to go-live with an anesthesia emr using epic software - (b) (6). one of the key components of \n",
      " peri-prosthetic leak. it was replaced with a sjm epic, size 23mm. pt is reportedly doing fine.\n",
      "cated in the iliac artery. during deployment of a epic- vascular stent the stent moved forward about 15m\n",
      "tudy and an icd was placed.the icd was a st. jude epic + vr model v-196. the icd lead was a st. jude ria\n",
      " /// it has been reported that the epic frame dropped below normal low height all the way\n",
      " gas flow of 0.0 l/min. the gas flow info sent to epic (hospital info system) was recorded as 0.0 l/min,\n",
      "on iliac artery.  during deployment of a 8x61x120 epic' vascular stent, \"\"something happened and the ste\n",
      "al record (emr). the ecg request is placed in the epic emr, sent to the philips trace mastervue. the ecg\n"
     ]
    }
   ],
   "source": [
    "positive_pattern = 'epic'\n",
    "negative_pattern = 'epic ([^.!? ]+ ){0,5}?(stent|valve|vascular|sds|implant)'\n",
    "matches = []\n",
    "\n",
    "# iterate through reports and return a list of match objects (for positive matches) \n",
    "for text in data['ed_text']:\n",
    "    match = re.search(positive_pattern, text.lower())\n",
    "    if match is not None:\n",
    "        if not re.search(negative_pattern, text.lower()):\n",
    "            matches.append(match)  # add the match object to the list\n",
    "                        \n",
    "for match in matches[:25]:\n",
    "    print(context(match, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Output the Data\n",
    "As you can see in the output above, there are still some irrelevant results, but the noise has been greatly reduced, and we can see more results related to the Epic system. There is definitely more filtering that can be done, so feel free to experiment some more. The final step is to 1) create a set of reports that meet our filtering requirements and 2) output these reports as a file. The `pandas` module provides easy functionality for these tasks.\n",
    "\n",
    "1. First, we create a function that takes a text string and returns True or False depending on whether or not it passes our test filter.\n",
    "2. Second, we use the [`apply`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.apply.html) function to create a new dataset comprised of all rows where the `ed_text` field passes our function.\n",
    "3. Finally, we write our filtered dataset to a CSV file using the [`to_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) function.\n",
    "\n",
    "Run the following cell. If you look at the output file, you will see that we've reduced our set from 1500 reports to 196! From here, we can tweak our code further, create additional filters, or start producing a training set for a machine learning algorithm. This code can be applied to any additional dataset that is similar to the original input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 1 ###\n",
    "def is_match(text):\n",
    "    text = text.lower()\n",
    "    positive_pattern = 'epic'\n",
    "    negative_pattern = 'epic ([^.!? ]+ ){0,5}?(stent|valve|vascular|sds|implant)'\n",
    "    \n",
    "    if re.search(positive_pattern, text):  # check for match of term \"epic\"\n",
    "        if not re.search(negative_pattern, text.lower()):  # check against exclusionary pattern\n",
    "            return True  # indicates that the text passes the filter\n",
    "        \n",
    "    return False  # default to False if text does not pass filter\n",
    "\n",
    "### Step 2 ###\n",
    "filtered_data = data[data.ed_text.apply(lambda x: is_match(x))]\n",
    "# add the following code in the line below to check the output: print(filtered_data)\n",
    "\n",
    "### Step 3 ###\n",
    "filtered_data.to_csv('EPIC_MAUDE_filtered.csv', index=False)  # feel free to change the output name/location"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
